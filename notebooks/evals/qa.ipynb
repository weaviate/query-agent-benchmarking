{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb3396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set environment variabels\n",
    "import os\n",
    "\n",
    "os.environ[\"WEAVIATE_URL\"] = \"\"\n",
    "os.environ[\"WEAVIATE_API_KEY\"] = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92275cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stuff\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from datasets import load_dataset\n",
    "import dspy\n",
    "import weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a45dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello! How can I help you today? ðŸ˜Š']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 9 fields but got 6: Expected `Message` - serialized value may not be as expected [input_value=Message(content='Hello! H...: None}, annotations=[]), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='st...ider_specific_fields={}), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "# dspy setup\n",
    "lm = dspy.LM(\n",
    "    \"openai/gpt-4.1\",\n",
    "    cache=False,\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "dspy.configure(lm=lm, track_usage=True)\n",
    "\n",
    "lm(\"say hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5954c0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 9 fields but got 6: Expected `Message` - serialized value may not be as expected [input_value=Message(content='[[ ## an...: None}, annotations=[]), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='st...ider_specific_fields={}), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='HyDE can refer to several things depending on the context, but most commonly:\\n\\n1. **HyDE (Hybrid Density Estimator)**: In artificial intelligence and large language models (LLMs), HyDE stands for \"Hypothetical Document Embeddings\". It is a method, introduced by OpenAI, for enhancing retrieval-augmented generation (RAG) systems. HyDE works by generating a hypothetical answer to a user\\'s query, then using the embedding (vector representation) of that hypothetical document to better match relevant real documents during retrieval from a database or corpus. This leads to improved information retrieval performance, as the search is guided by a synthesized, context-rich sample.\\n\\n2. **Hyde (Other meanings)**:\\n   - It could refer to the character \"Hyde\" from the classic novel \"Strange Case of Dr Jekyll and Mr Hyde\" by Robert Louis Stevenson.\\n   - In music, Hyde is a well-known Japanese singer.\\n   - There are cities named Hyde (e.g., Hyde, Greater Manchester in England).\\n\\n**In AI and LLM contexts, \"HyDE\" almost always refers to the retrieval augmentation technique described above.**'\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GenerateAnswerFromParameters(dspy.Signature):\n",
    "    \"\"\"Answer the question as well as you can.\"\"\"\n",
    "\n",
    "    question: str = dspy.InputField(description=\"The question to answer.\")\n",
    "    answer: str = dspy.OutputField(description=\"The answer to the question.\")\n",
    "\n",
    "qa_system = dspy.Predict(GenerateAnswerFromParameters)\n",
    "\n",
    "qa_system(question=\"What is HyDE?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0c2fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define RAG systems\n",
    "\n",
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Assess the context and answer the question.\"\"\"\n",
    "\n",
    "    question: str = dspy.InputField(description=\"The question to answer.\")\n",
    "    context: list[str] | list[dspy.Image] = dspy.InputField(description=\"The context to use to answer the question.\")\n",
    "    answer: str = dspy.OutputField(description=\"The answer to the question.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b06a52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 9 fields but got 6: Expected `Message` - serialized value may not be as expected [input_value=Message(content='[[ ## sc...: None}, annotations=[]), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='st...ider_specific_fields={}), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    score=False\n",
      ")\n",
      "Prediction(\n",
      "    score=True\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# llm as judge\n",
    "class AssessAlignmentScore(dspy.Signature):\n",
    "    \"\"\"You are an expert grader assessing if a system's answer is semantically aligned with the correct answer.\n",
    "    Only return True if the system answer has essentially the same meaning as the correct answer.\n",
    "    If the system answer misses key aspects or meaning, return False.\n",
    "    \"\"\"\n",
    "\n",
    "    question: str = dspy.InputField(description=\"The question asked.\")\n",
    "    system_answer: str = dspy.InputField(description=\"The answer generated by the system.\")\n",
    "    correct_answer: str = dspy.InputField(description=\"The reference answer containing the correct and complete information.\")\n",
    "    score: bool = dspy.OutputField(description=\"True if system_answer is equivalent in meaning to correct_answer, otherwise False.\")\n",
    "\n",
    "judge = dspy.Predict(AssessAlignmentScore)\n",
    "\n",
    "test_question = \"What is HyDE?\"\n",
    "correct_answer = \"HyDE stands for Hypothetical Document Embeddings, a technique for improving retrieval in AI systems by generating hypothetical answers and using their embeddings.\"\n",
    "\n",
    "# System answer missing key aspect (embeddings)\n",
    "incorrect_answer = \"HyDE is a technique for improving retrieval in AI systems by generating hypothetical answers.\"\n",
    "# System answer rewords but covers all key ideas\n",
    "acceptable_answer = \"Hypothetical Document Embeddings (HyDE) is a method to help AI retrieval by creating hypothetical documents as sample answers and using their vector representations.\"\n",
    "\n",
    "response = judge(question=test_question, system_answer=incorrect_answer, correct_answer=correct_answer)\n",
    "print(response)\n",
    "response = judge(question=test_question, system_answer=acceptable_answer, correct_answer=correct_answer)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81134a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'openai/gpt-4.1': {'completion_tokens': 12,\n",
       "  'prompt_tokens': 349,\n",
       "  'total_tokens': 361,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0,\n",
       "   'text_tokens': None},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0,\n",
       "   'cached_tokens': 0,\n",
       "   'text_tokens': None,\n",
       "   'image_tokens': None}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.get_lm_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "from datasets import load_dataset\n",
    "\n",
    "queries = load_dataset(\"weaviate/irpapers-queries\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f34d70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 9 fields but got 6: Expected `Message` - serialized value may not be as expected [input_value=Message(content='[[ ## an...: None}, annotations=[]), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='st...ider_specific_fields={}), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "alignment_scores, input_tokens, output_tokens = [], [], []\n",
    "\n",
    "K = 3\n",
    "\n",
    "start = time.time()\n",
    "for idx, query in enumerate(queries):\n",
    "    if idx % 5 == 4:\n",
    "        print(f\"Processed {idx+1} queries in {time.time() - start} seconds...\")\n",
    "    test_query, ground_truth_answer = query[\"question\"], query[\"answer\"]\n",
    "    qa_system_response = qa_system(\n",
    "        question=test_query\n",
    "    )\n",
    "    usage_dict = qa_system_response.get_lm_usage()[\"openai/gpt-4.1\"]\n",
    "    input_tokens.append(usage_dict[\"prompt_tokens\"])\n",
    "    output_tokens.append(usage_dict[\"completion_tokens\"])\n",
    "\n",
    "    ensemble_votes = 0\n",
    "    for judge_predictions in range(K):\n",
    "        lm_judge_response = judge(\n",
    "            question=test_query,\n",
    "            system_answer=qa_system_response.answer,\n",
    "            correct_answer=ground_truth_answer\n",
    "        )\n",
    "        if lm_judge_response.score:\n",
    "            ensemble_votes += 1\n",
    "    if ensemble_votes >= K / 2:\n",
    "        alignment_scores.append(1)\n",
    "    else:\n",
    "        alignment_scores.append(0)\n",
    "\n",
    "alignment_scores = np.array(alignment_scores)\n",
    "input_tokens = np.array(input_tokens)\n",
    "output_tokens = np.array(output_tokens)\n",
    "\n",
    "print(alignment_scores.mean())\n",
    "print(input_tokens.mean())\n",
    "print(output_tokens.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1713851d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
