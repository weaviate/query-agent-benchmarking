# 2. Run Custom Evals

The `run_eval` method further enables passing in a custom document, `DocsCollection` and/or query collection, `QueriesCollection`.

```python
import query_agent_benchmarking

from query_agent_benchmarking.models import (
    DocsCollection,
    QueriesCollection,
)

docs_collection = DocsCollection(
    collection_name="BrightBiology", # name of the collection to search through
    content_key="content", # searchable property name
    id_key="dataset_id", # dataset id property
)

queries_collection = QueriesCollection(
    collection_name="SyntheticBrightBiology", # name of collection containing queries
    query_content_key="simulated_user_query", # property name containing the query
    gold_ids_key="dataset_ids", # property name containing the document ids the query should return
)

query_agent_benchmarking.run_eval(
    docs_collection=docs_collection,
    queries=queries_collection,
)
```
