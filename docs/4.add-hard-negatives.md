# 4. Hard Negative Miner

As a quick reminder, in Information Retrieval benchmarking, for each query, we are looking to see where the labeled ground truth, "gold", document is ranked by the search system. Now let's say the search system indeed found the gold document in the top 10, but it is ranked at position 4, :/. That's still pretty encouraging if we are searching out of say, 100s of thousands, millions, ... of objects!

The 3 documents ranked ahead of the gold document in this example are particularly interesting because they are likely to have some kind of relevance to the query. These documents are called "hard negatives", because unlike say documents 100,000 to 100,003, assessing their relevance is confusing the search system.

Hard negatives are particularly useful for training search models. The following API will help you mine out hard negatives from your custom benchmarks, just specify which `hard_negative_key` to store the hard negative and the number of negatives to mine per query, `negatives_per_query`.


```python
import query_agent_benchmarking

from query_agent_benchmarking.models import (
    DocsCollection,
    QueriesCollection,
)

docs_collection = DocsCollection(
    collection_name="BrightBiology", # name of the collection to search through
    content_key="content", # searchable property name
    id_key="dataset_id", # dataset id property
)

queries_collection = QueriesCollection(
    collection_name="SyntheticBrightBiology", # name of collection containing queries
    query_content_key="simulated_user_query", # property name containing the query
    gold_ids_key="dataset_ids", # property name containing the document ids the query should return
)

query_agent_benchmarking.add_hard_negatives(
    hard_negative_key="hard_negative",
    negatives_per_query=5,
    docs_collection=docs_collection,
    queries=queries_collection,
    query_samples=100,
)
```