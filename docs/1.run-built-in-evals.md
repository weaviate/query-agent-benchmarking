# 1. Run Evals

```python
import query_agent_benchmarking

# reads parameters from default config path

query_agent_benchmarking.run_eval()

# pass in override params

query_agent_benchmarking.run_eval(
	dataset_name="bright/psychology",
    agent="query-agent-search-mode"
)
```